{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b83ce642-c704-4675-95d8-3235ab3b3aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENE added to ENE for SO2\n",
      "REF_TRF added to ENE for SO2\n",
      "PRO_FFF added to ENE for SO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/126931.tmpdir/ipykernel_625/1263969286.py:144: UserWarning: WARNING: missing_value not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  v61 = data.variables[variable_name][:]\n",
      "/tmp/126931.tmpdir/ipykernel_625/1263969286.py:150: RuntimeWarning: invalid value encountered in divide\n",
      "  scale = np.divide(annual_data[sector],masked_v61ann).data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2390369e-12\n",
      "11709.885\n",
      "2.3137787e-12\n",
      "2.7854732e-12\n",
      "11709.885\n",
      "1.4597599e-12\n",
      "2.3246559e-12\n",
      "11709.885\n",
      "2.0158645e-12\n",
      "2.0200209e-12\n",
      "11709.885\n",
      "1.9877331e-12\n",
      "1.9851959e-12\n",
      "11709.885\n",
      "1.168496e-12\n",
      "2.32457e-12\n",
      "11709.885\n",
      "1.9281749e-12\n",
      "2.1934776e-12\n",
      "11709.885\n",
      "1.2139298e-12\n",
      "2.2251192e-12\n",
      "11709.885\n",
      "1.2184262e-12\n",
      "2.1773468e-12\n",
      "11709.885\n",
      "1.89702e-12\n",
      "2.220068e-12\n",
      "11709.885\n",
      "1.9733958e-12\n",
      "2.2982796e-12\n",
      "11709.885\n",
      "1.2782546e-12\n",
      "2.4128774e-12\n",
      "11709.885\n",
      "2.7951467e-12\n",
      "SO2 ENE seasonalized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the base directory where your .nc files are stored\n",
    "in_dir = '/storage1/fs1/rvmartin/Active/haihuizhu/4.SPARTAN_SO4/EDGAR/EDGARv81/raw_data'\n",
    "out_dir = '/storage1/fs1/rvmartin/Active/haihuizhu/4.SPARTAN_SO4/EDGAR/EDGARv81/'\n",
    "v61_dir = '/storage1/fs1/rvmartin/Active/haihuizhu/4.SPARTAN_SO4/EDGAR/EDGARv61/'\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(out_dir, exist_ok=True)            \n",
    "\n",
    "# species\n",
    "# species = [\"BC\", \"CO\", \"NH3\", \"NMVOC\", \"NOx\", \"OC\", \"PM10\", \"PM2.5\", \"SO2\"] \n",
    "species = [\"SO2\"] \n",
    "years = ['2021'] \n",
    "fin_sec = ['ENE']\n",
    "sec_group = {\n",
    "    'ENE':['ENE','REF_TRF','PRO_FFF'], #### change to PRO_FFF #3\n",
    "    'IND':['IND','CHE','FOO_PAP','IRO','NEU','NFE','NMM'],#7\n",
    "    'TRA':['TNR_Other','TRO'], #### lump TRO #2\n",
    "    'RCO':['RCO'],\n",
    "    'SLV':['PRU_SOL'],\n",
    "    'AGR':['MNM'],\n",
    "    'AVA':['TNR_Aviation_CDS','TNR_Aviation_CRS','TNR_Aviation_LTO','TNR_Aviation_SPS'], #4\n",
    "    'SHP':['TNR_Ship'],\n",
    "\t'WST':['SWD_INC','SWD_LDF','WWT'],  #3\n",
    "\t'AWB':['AWB'],\n",
    "\t'SOL':['AGS'] \n",
    "    }\n",
    "\n",
    "# not used in the script but can be compared with log file\n",
    "spec_sec = {\n",
    "    'sector_BC':     ['ENE', 'IND', 'RCO', 'TRA', 'AWB', 'WST', 'SHP', 'AVA'],\n",
    "    'sector_CO':     ['ENE', 'IND', 'RCO', 'TRA', 'AWB', 'WST', 'SHP', 'AVA'],\n",
    "    'sector_OC':     ['ENE', 'IND', 'RCO', 'TRA', 'AWB', 'WST', 'SHP', 'AVA'],\n",
    "    'sector_SO2':    ['ENE', 'IND', 'RCO', 'TRA', 'AWB', 'WST', 'SHP', 'AVA'],\n",
    "    'sector_NOx':    ['ENE', 'IND', 'RCO', 'TRA', 'AGR', 'SOL', 'AWB', 'WST', 'SHP', 'AVA'],\n",
    "    'sector_NH3':    ['ENE', 'IND', 'RCO', 'TRA', 'AGR', 'SOL', 'AWB', 'WST', 'SLV', 'SHP', 'AVA'],\n",
    "    'sector_NMVOC' : ['ENE', 'IND', 'RCO', 'TRA', 'AGR', 'SOL', 'AWB', 'WST', 'SLV', 'SHP', 'AVA'],\n",
    "    'sector_PM2.5' : ['ENE', 'IND', 'RCO', 'TRA', 'AGR', 'SOL', 'AWB', 'WST', 'SLV', 'SHP', 'AVA'],\n",
    "    'sector_PM10'  : ['ENE', 'IND', 'RCO', 'TRA', 'AGR', 'SOL', 'AWB', 'WST', 'SLV', 'SHP', 'AVA']\n",
    "}\n",
    "\n",
    "unit = 'kg m-2 s-1'\n",
    "\n",
    "def sort_lon(data):\n",
    "    # Assume that dimension sizes are constant across all files\n",
    "    lat = data.variables['lat'][:]\n",
    "    lon = data.variables['lon'][:]\n",
    "    # change lon to [-180 to 180]\n",
    "    lon_adjusted = np.where(lon > 180, lon - 360, lon)\n",
    "    sorted_indices = np.argsort(lon_adjusted)\n",
    "    lon = lon_adjusted[sorted_indices]\n",
    "    return lat,lon,sorted_indices\n",
    "\n",
    "def check_unit(unit,data,fname,spec):\n",
    "    unit2 = data.variables['fluxes'].units\n",
    "    if unit2 != unit:\n",
    "        print(f'WARNING: {fname} unit {unit2} not correct!')\n",
    "\n",
    "def datacomp(indata,name):\n",
    "    # Count the number of NaN values\n",
    "    print(f\"{name}:\")\n",
    "    numel = indata.size\n",
    "    print(f\"Number of NaNs: {np.isnan(indata).sum()}, {np.isnan(indata).sum()/numel*100 :.2f}%\")\n",
    "    print(f\"Number of zeros: {np.sum(indata == 0)}, {np.sum(indata == 0)/numel*100:.2f}%\")\n",
    "    print(f\"Number of positive: {np.sum(indata >0)},{np.sum(indata >0)/numel*100:.2f}%\")\n",
    "    print(f\"Number of negative: {np.sum(indata <0)},{np.sum(indata <0)/numel*100:.2f}%\")\n",
    "    print(f\"Number of Inf: {np.isinf(indata).sum()},{np.isinf(indata).sum()/numel*100:.2f}%\")\n",
    "    # Use np.vectorize to apply the `type` function to each element\n",
    "\n",
    "def get_scale(indata):\n",
    "    avg = np.mean(indata,axis=0)\n",
    "    # avg0 = np.copy(avg)\n",
    "    avg[avg==0] = 1\n",
    "    scale = np.nan*indata\n",
    "    for idx in range (0,12):\n",
    "        tscale = indata[idx,:,:]/avg\n",
    "        # tscale[avg0==0] = 1 # when avg == 0, emissions are 0 across 12 months. scale should be 1. \n",
    "        scale[idx,:,:] = tscale\n",
    "    # scale = np.nan_to_num(scale,nan=1)\n",
    "    \n",
    "    datacomp(indata,'original data') # show data type in arrays for debugging purpose\n",
    "    datacomp(avg,'avg')\n",
    "    datacomp(scale,'scale')\n",
    "\n",
    "    # for debug purpose\n",
    "    season_var = np.mean(indata,axis=(1,2))\n",
    "    print(f'seasonal variation')\n",
    "    for id in range(0,4):\n",
    "        print(f'{season_var[id]:.2e}')\n",
    "\n",
    "    scalers = np.mean(scale,axis=(1,2))\n",
    "    print(f'scaler variation')\n",
    "    for id in range(0,4):\n",
    "        print(f'{scalers[id]:.2f}')\n",
    "    \n",
    "    return scale\n",
    "\n",
    "for year in years:\n",
    "    for spec in species:\n",
    "        annual_data = {}\n",
    "        monthly_data = {}\n",
    "        \n",
    "        for sector in fin_sec:\n",
    "            annual_data[sector] = None  # Initialize \n",
    "            # start_time = datetime.now() # tracking time for each sector\n",
    "\n",
    "            for subsec in sec_group[sector]:\n",
    "                # standard file path - with 'monthly' \n",
    "                fpath = f'{in_dir}/{spec}/v8.1_FT2022_AP_{spec}_{year}_{subsec}_flx_nc'\n",
    "\n",
    "                if os.path.isdir(fpath):\n",
    "                    fname = f'{fpath}/v8.1_FT2022_AP_{spec}_{year}_{subsec}_flx.nc'\n",
    "                    with nc.Dataset(fname, 'r') as data:\n",
    "                        if 'lat' not in globals():\n",
    "                            lat,lon,sorted_indices = sort_lon(data)\n",
    "\n",
    "                        check_unit(unit,data,fname,spec)\n",
    "\n",
    "                        fluxes = data.variables['fluxes'][:]\n",
    "                        fluxes = fluxes[:, sorted_indices]\n",
    "                        \n",
    "                        if annual_data[sector] is None:\n",
    "                            annual_data[sector] = fluxes # add to current values\n",
    "                        else:\n",
    "                            annual_data[sector] += fluxes \n",
    "                            \n",
    "                    print(f'{subsec} added to {sector} for {spec}')\n",
    "                    \n",
    "                else: \n",
    "                    print(f'{subsec} for {spec} not found') \n",
    "                             \n",
    "            # load v61 data to scale annual to monthly\n",
    "            if annual_data[sector] is not None:\n",
    "                monthly_data[sector] = [None] * 12 # Initialize list for 12 months\n",
    "                filev61 = f'{v61_dir}/EDGARv6.1_{spec}_2018.0.1x0.1.nc'\n",
    "                data = nc.Dataset(filev61, 'r')\n",
    "                variable_name = '{}_{}'.format(spec, sector)\n",
    "                if variable_name in data.variables:\n",
    "                    v61 = data.variables[variable_name][:]\n",
    "                    v61ann = np.mean(v61,axis=0)\n",
    "                    mask = v61ann == 0\n",
    "                    v61ann[mask] = annual_data[sector][mask]\n",
    "                    mask2 = v61ann == 0\n",
    "                    masked_v61ann = np.ma.masked_array(v61ann,mask2)\n",
    "                    scale = np.divide(annual_data[sector],masked_v61ann).data\n",
    "                    # season_scale = get_scale(v61)\n",
    "                    for mn in range(0,12): \n",
    "                        # assumptions here: only annual mean == 0 are missing values. In v61, if there are some months with values,\n",
    "                        # some months don't, assuming emission for these months are 0. [Although it is possible that emssion can \n",
    "                        # be missing for some months, not the entire year] \n",
    "                        v61[mn, :, :][mask] = annual_data[sector][mask]  # Replace missing values with v81 values\n",
    "                        monthly_data[sector][mn] = v61[mn,:,:] * scale\n",
    "                        print(np.mean(np.mean(v61[mn,:,:])))\n",
    "                        print(np.mean(np.mean(scale)))\n",
    "                        print(np.mean(np.mean(monthly_data[sector][mn])))\n",
    "\n",
    "\n",
    "                    print(f'{spec} {sector} seasonalized\\n')   \n",
    "\n",
    "                else:\n",
    "                    print(f'{spec} {sector} seasonal data not found\\n')  \n",
    "                \n",
    "            # end_time = datetime.now()\n",
    "            # elapsed_time = end_time - start_time\n",
    "            # print(\"Elapsed time:\", elapsed_time)\n",
    "           \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16244f31-c0d2-43aa-82de-5e0585de7940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21685627000.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2533d-080e-4c11-881a-014569635886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a7841-03f2-4437-92fd-d9ab179b85a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
